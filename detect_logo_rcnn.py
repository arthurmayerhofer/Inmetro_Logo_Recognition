# import the necessary packages
from library.nms import non_max_suppression
from library import config
import tensorflow
from tensorflow.keras.applications.xception import preprocess_input
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.models import load_model
import numpy as np
import argparse
import imutils
import pickle
import cv2
# construct the argument parser and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-i", "--image", required=True,
	help="path to input image")
args = vars(ap.parse_args())

# load the our fine-tuned model and label binarizer from disk
print("[INFO] loading model and label binarizer...")
model = load_model(config.MODEL_PATH)
lb = pickle.loads(open(config.ENCODER_PATH, "rb").read())
# load the input image from disk
image = cv2.imread(args["image"])
image = imutils.resize(image, width=500)
# run selective search on the image to generate bounding box proposal
# regions
print("[INFO] running selective search...")
ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
ss.setBaseImage(image)
ss.switchToSelectiveSearchFast()
rects = ss.process()

# initialize the list of region proposals that we'll be classifying
# along with their associated bounding boxes
proposals = []
boxes = []
# loop over the region proposal bounding box coordinates generated by
# running selective search
for (x, y, w, h) in rects[:config.MAX_PROPOSALS_INFER]:
	# extract the region from the input image, convert it from BGR to
	# RGB channel ordering, and then resize it to the required input
	# dimensions of our trained CNN
	roi = image[y:y + h, x:x + w]
	roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)
	roi = cv2.resize(roi, config.INPUT_DIMS,
		interpolation=cv2.INTER_CUBIC)
	# further preprocess the ROI
	roi = img_to_array(roi)
	roi = preprocess_input(roi)
	# update our proposals and bounding boxes lists
	proposals.append(roi)
	boxes.append((x, y, x + w, y + h))

# convert the proposals and bounding boxes into NumPy arrays
proposals = np.array(proposals, dtype="float32")
boxes = np.array(boxes, dtype="int32")
print("[INFO] proposal shape: {}".format(proposals.shape))
# classify each of the proposal ROIs using fine-tuned model
print("[INFO] classifying proposals...")
proba = model.predict(proposals)

# find the index of all predictions that are positive for the
# "logo" class
labels = lb.classes_[np.argmax(proba, axis=1)]
idxs = np.where(labels == "logo")[0]
# use the indexes to extract all bounding boxes and associated class
# label probabilities associated with the "logo" class
boxes = boxes[idxs]
proba = proba[idxs][:, 0]
print(proba)
print("[INFO] Total de Área(s) Detectadas: " + str(len(boxes)))
# further filter indexes by enforcing a minimum prediction
# probability be met
idxs = np.where(proba >= config.MIN_PROBA)
boxes = boxes[idxs]
proba = proba[idxs]
print(proba)
print("[INFO] Área(s) de precisão acima de 95%: " + str(len(boxes)))
# set image copy and image backgroud
result = image.copy()
back_1 = np.full((image.shape), (0,255,0), dtype=np.uint8)

print(len(proba))

if len(proba) == 0:
	print("[NOT DETECTED]")
	
	text_2 = "Not Detected"
	cv2.putText(result, text_2, (x,y), cv2.FONT_HERSHEY_DUPLEX, 2, (0,0,255), 2)
	
else:

	#i = np.argmax(proba)
	i = 0
	# draw the bounding box, label, and maximum probability on the image
	(startX, startY, endX, endY) = boxes[i]
	cv2.rectangle(result, (startX, startY), (endX, endY),
		(0, 255, 0), 1)
	# write text
	l = image.shape[1] - startX
	x = startX - 80 if l < 100 else startX 
	y = startY - 5 if startY - 5 > 5 else startY + 5
	text_1 = "Logo: {:.2f}%".format(float(proba[i] * 100))
	#text = "Logo: " + str(round(float(proba[i] * 100)),2) + "%"
	cv2.putText(back_1, text_1, (x,y), cv2.FONT_HERSHEY_DUPLEX, 0.5, (255,255,255), 1)
	# draw text background
	x,y,w,h = cv2.boundingRect(back_1[:,:,2])
	result[y:y+h, x:x+w] = back_1[y:y+h, x:x+w]

# show the result
cv2.imshow("RESULT", result)
#cv2.imwrite("detect.jpg", result)

cv2.waitKey(0)  